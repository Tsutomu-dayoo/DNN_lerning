{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Binary_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM6FBX/lwkyqm/pMlqGwpoJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tsutomu-dayoo/DNN_lerning/blob/master/Binary_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SM5FTNUkuNCL",
        "colab_type": "code",
        "outputId": "521fb76f-617f-47c9-ea64-278bf93f38cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "xs = np.array([[0,0], [0,1], [1,0], [1,1]], dtype=np.float32)\n",
        "#ts = np.array([[0], [0], [0], [1]], dtype=np.float32)\n",
        "ts = np.array([[0], [1], [1], [0]], dtype=np.float32)\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "lr = 0.1\n",
        "\n",
        "class FullyConnectedLayer():\n",
        "  def __init__(self, in_n, out_n, use_bias=True, activation=None):#入力、出力、バイアス、活性化関数\n",
        "    self.w = np.random.normal(0,1,[in_n, out_n])\n",
        "    if use_bias:\n",
        "      self.b = np.random.normal(0,1,[out_n])\n",
        "    else:\n",
        "      self.b = None\n",
        "    if activation is not None:\n",
        "      self.activation = activation\n",
        "    else:\n",
        "      self.activation = None\n",
        "      \n",
        "  def forward(self, feature_in):\n",
        "    self.x_in = feature_in\n",
        "    z = np.dot(feature_in,self.w)\n",
        "    if self.b is not None:\n",
        "      z += self.b\n",
        "    if self.activation is not None:\n",
        "      x = self.activation(z)\n",
        "      self.x_out = x\n",
        "\n",
        "    return x\n",
        "\n",
        "  def backward(self, w_pro, grad_pro):\n",
        "      grad = np.dot(grad_pro, w_pro.T)\n",
        "      if self.activation is sigmoid:\n",
        "          grad *= (self.x_out * (1 - self.x_out))\n",
        "      grad_w = np.dot(self.x_in.T, grad)\n",
        "      self.w -= lr * grad_w\n",
        "\n",
        "      if self.b is not None:\n",
        "          grad_b = np.dot(np.ones([grad.shape[0]]), grad)\n",
        "          self.b -= lr * grad_b\n",
        "\n",
        "      return grad\n",
        "\n",
        "\n",
        "class Model():\n",
        "  def __init__(self, *args):\n",
        "    self.layers = args #設定したレイヤーの数だけ層を作る\n",
        "\n",
        "  def forward(self, x):\n",
        "    for layer in self.layers: #;for layer<-ここで宣言してる？\n",
        "      x = layer.forward(x)\n",
        "    self.output = x\n",
        "\n",
        "    return x\n",
        "\n",
        "  def backward(self, t):\n",
        "    En = (self.output - t) * self.output * (1 - self.output)\n",
        "    grad_pro = En\n",
        "    w_pro = np.eye(En.shape[-1])\n",
        "        \n",
        "    for i, layer in enumerate(self.layers[::-1]):\n",
        "            grad_pro = layer.backward(w_pro=w_pro, grad_pro=grad_pro)\n",
        "            w_pro = layer.w\n",
        "\n",
        "model = Model(FullyConnectedLayer(in_n=2, out_n=64, activation=sigmoid),\n",
        "              FullyConnectedLayer(in_n=64, out_n=32, activation=sigmoid),\n",
        "              FullyConnectedLayer(in_n=32, out_n=1, activation=sigmoid))\n",
        "\n",
        "\n",
        "for ite in range(10000):\n",
        "    ite += 1\n",
        "\n",
        "    model.forward(xs)　#入力から予測値を算出\n",
        "    model.backward(ts) #バックプロパゲーションにより重みを更新\n",
        "\n",
        "\n",
        "# test\n",
        "for i in range(4):\n",
        "    out = model.forward(xs[i])\n",
        "    print(\"in >>\", xs[i], \", out >>\", out)\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "in >> [0. 0.] , out >> [0.07853192]\n",
            "in >> [0. 1.] , out >> [0.92135039]\n",
            "in >> [1. 0.] , out >> [0.91315036]\n",
            "in >> [1. 1.] , out >> [0.08539355]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fduxm3-WFkPJ",
        "colab_type": "code",
        "outputId": "443a0ef1-6f03-4ef0-a0ba-13379be50e9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "#XOR Gate\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "xs = np.array(((0,0), (0,1), (1,0), (1,1)), dtype=np.float32)\n",
        "ts = np.array([[0], [1], [1], [0]], dtype=np.float32)\n",
        "\n",
        "lrs = [0.1, 0.01] #学習率\n",
        "lr = lrs[0]\n",
        "\n",
        "np.random.seed(0) # 乱数生成\n",
        "w1 = np.random.normal(0.,1,[2,2])\n",
        "b1= np.random.normal(0.,1,[2])\n",
        "w_out = np.random.normal(0,1,[2,1])\n",
        "b_out = np.random.normal(0.,1,[1])\n",
        "print(\"weight1 >>\\n\", w1)\n",
        "print(\"bias1 >>\\n\", b1)\n",
        "print(\"weight_out >>\\m\", w_out)\n",
        "print(\"bias_out >>\\n\", b_out)\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1/(1+np.exp(-x))\n",
        "\n",
        "#train\n",
        "ite = 0\n",
        "#while True:\n",
        "for i in range(5000):\n",
        "  ite += 1\n",
        "  z1 = sigmoid(np.dot(xs,w1) + b1) #中間層の出力\n",
        "  ys = sigmoid(np.dot(z1,w_out) + b_out)\n",
        "  #print(\"iteration:\",ite,\" ys>> \",ys)\n",
        "\n",
        "  #update parameters\n",
        "  En = (ys - ts) * ys * (1 - ys)\n",
        "  grad_wout = np.dot(z1.T,En)\n",
        "  grad_bout =  np.dot(np.ones([En.shape[0]]), En)\n",
        "  w_out -= lr * grad_wout\n",
        "  b_out -= lr * grad_bout\n",
        "\n",
        "  grad_u = np.dot(En, w_out.T) * z1 * (1-z1)\n",
        "  grad_w1 = np.dot(xs.T, grad_u)\n",
        "  grad_b1 = np.dot(np.ones([En.shape[0]]), grad_u)\n",
        "  w1 -= lr * grad_w1\n",
        "  b1 -= lr * grad_b1\n",
        "print(\"training finished!\")\n",
        "# test\n",
        "for i in range(4):\n",
        "  z1 = sigmoid(np.dot(xs[i],w1) + b1) \n",
        "  ys = sigmoid(np.dot(z1,w_out) + b_out)\n",
        "  print(\"in >>\", xs[i], \", out >>\", ys) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weight1 >>\n",
            " [[1.76405235 0.40015721]\n",
            " [0.97873798 2.2408932 ]]\n",
            "bias1 >>\n",
            " [ 1.86755799 -0.97727788]\n",
            "weight_out >>\\m [[ 0.95008842]\n",
            " [-0.15135721]]\n",
            "bias_out >>\n",
            " [-0.10321885]\n",
            "training finished!\n",
            "in >> [0. 0.] , out >> [0.09624175]\n",
            "in >> [0. 1.] , out >> [0.90638069]\n",
            "in >> [1. 0.] , out >> [0.90588055]\n",
            "in >> [1. 1.] , out >> [0.10374782]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "038TNDPBKnyO",
        "colab_type": "code",
        "outputId": "82e5d105-986c-48b9-b760-d15be9d44728",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "#AND Gate\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "xs = np.array(((0,0), (0,1), (1,0), (1,1)), dtype=np.float32)\n",
        "ts = np.array(((0), (0), (0), (1)), dtype=np.float32)\n",
        "\n",
        "lrs = [0.1, 0.01] #学習率\n",
        "lr = lrs[0]\n",
        "\n",
        "np.random.seed(0) # 乱数生成\n",
        "w = np.random.normal(0.,1,(2))\n",
        "b = np.random.normal(0.,1,(1))\n",
        "print(\"w >>\",w)\n",
        "print(\"b >>\",b)\n",
        "\n",
        "_xs = np.hstack([xs, [[1] for i in range(4)]])\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1/(1+np.exp(-x))\n",
        "\n",
        "#train\n",
        "ite = 0\n",
        "#while True:\n",
        "for i in range(5):\n",
        "  ite += 1\n",
        "  ys = sigmoid(np.dot(xs,w) + b)\n",
        "  #print(\"iteration:\",ite,\" ys>> \",ys)\n",
        "\n",
        "  #update parameters\n",
        "  En = -(ts - ys) * ys * (1 - ys)\n",
        "  grad_w = np.dot(xs.T, En)\n",
        "  grad_b = np.dot(np.ones([En.shape[0]]), En)\n",
        "  print(\"En\",En)\n",
        "  print([En.shape[0]])\n",
        "  print(\"grad_b>>\",grad_b)\n",
        "  w -= lr * grad_w\n",
        "  b -= lr * grad_b\n",
        "print(\"training finished!\")\n",
        "# test\n",
        "for i in range(4):\n",
        "    ys = sigmoid(np.dot(xs,w) + b)\n",
        "    print(\"in >>\", xs[i], \", out >>\", ys[i]) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "w >> [1.76405235 0.40015721]\n",
            "b >> [0.97873798]\n",
            "En>> [ 0.14430711  0.12837771  0.05339719 -0.00164068]\n",
            "[4]\n",
            "grad_b>> 0.32444133633371347\n",
            "En>> [ 0.14510931  0.13062991  0.05506028 -0.00180273]\n",
            "[4]\n",
            "grad_b>> 0.32899675844335113\n",
            "En>> [ 0.14583255  0.13281874  0.05678869 -0.00198317]\n",
            "[4]\n",
            "grad_b>> 0.333456802754926\n",
            "En>> [ 0.14647007  0.13492902  0.05858384 -0.00218418]\n",
            "[4]\n",
            "grad_b>> 0.3377987577234487\n",
            "En>> [ 0.14701508  0.13694468  0.06044693 -0.00240816]\n",
            "[4]\n",
            "grad_b>> 0.3419985272433976\n",
            "training finished!\n",
            "in >> [0. 0.] , out >> 0.6925501704746141\n",
            "in >> [0. 1.] , out >> 0.7589365245478741\n",
            "in >> [1. 0.] , out >> 0.9274858155696656\n",
            "in >> [1. 1.] , out >> 0.9470239473786904\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZmGNMyHVlWN",
        "colab_type": "code",
        "outputId": "dce5ccb4-53b2-46bc-849b-1183e44e3268",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "xs = np.array([[0,0], [0,1], [1,0], [1,1]], dtype=np.float32)\n",
        "ts = np.array([[0], [1], [1], [0]], dtype=np.float32)\n",
        "\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "class FullyConnectedLayer():\n",
        "    def __init__(self, in_n, out_n, use_bias=True, activation=None):\n",
        "        self.w = np.random.normal(0, 1, [in_n, out_n])\n",
        "        if use_bias:\n",
        "            self.b = np.random.normal(0, 1, [out_n])\n",
        "        else:\n",
        "            self.b = None\n",
        "        if activation is not None:\n",
        "            self.activation = activation\n",
        "        else:\n",
        "            self.activation = None\n",
        "\n",
        "    def set_lr(self, lr=0.1):\n",
        "        self.lr = lr\n",
        "\n",
        "    def forward(self, feature_in):\n",
        "        self.x_in = feature_in\n",
        "        x = np.dot(feature_in, self.w)\n",
        "        \n",
        "        if self.b is not None:\n",
        "            x += self.b\n",
        "            \n",
        "        if self.activation is not None:\n",
        "            x = self.activation(x)\n",
        "        self.x_out = x\n",
        "        \n",
        "        return x\n",
        "\n",
        "    \n",
        "    def backward(self, w_pro, grad_pro):\n",
        "        grad = np.dot(grad_pro, w_pro.T)\n",
        "        if self.activation is sigmoid:\n",
        "            grad *= (self.x_out * (1 - self.x_out))\n",
        "        grad_w = np.dot(self.x_in.T, grad)\n",
        "        self.w -= self.lr * grad_w\n",
        "\n",
        "        if self.b is not None:\n",
        "            grad_b = np.dot(np.ones([grad.shape[0]]), grad)\n",
        "            self.b -= self.lr * grad_b\n",
        "\n",
        "        return grad\n",
        "\n",
        "    \n",
        "class Model():\n",
        "    def __init__(self, *args, lr=0.1):\n",
        "        self.layers = args\n",
        "        for l in self.layers:\n",
        "            l.set_lr(lr=lr)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer.forward(x)\n",
        "        self.output = x\n",
        "        \n",
        "        return x\n",
        "\n",
        "    def backward(self, t):\n",
        "        En = (self.output - t) * self.output * (1 - self.output)\n",
        "        grad_pro = En\n",
        "        w_pro = np.eye(En.shape[-1])\n",
        "        \n",
        "        for i, layer in enumerate(self.layers[::-1]):\n",
        "            grad_pro = layer.backward(w_pro=w_pro, grad_pro=grad_pro)\n",
        "            w_pro = layer.w\n",
        "            \n",
        "\n",
        "\n",
        "model = Model(FullyConnectedLayer(in_n=2, out_n=64, activation=sigmoid),\n",
        "              FullyConnectedLayer(in_n=64, out_n=32, activation=sigmoid),\n",
        "              FullyConnectedLayer(in_n=32, out_n=1, activation=sigmoid), lr=0.1)\n",
        "\n",
        "\n",
        "for ite in range(10000):\n",
        "    ite += 1\n",
        "\n",
        "    model.forward(xs)\n",
        "    model.backward(ts)\n",
        "\n",
        "\n",
        "# test\n",
        "for i in range(4):\n",
        "    out = model.forward(xs[i])\n",
        "    print(\"in >>\", xs[i], \", out >>\", out)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "in >> [0. 0.] , out >> [0.07853192]\n",
            "in >> [0. 1.] , out >> [0.92135039]\n",
            "in >> [1. 0.] , out >> [0.91315036]\n",
            "in >> [1. 1.] , out >> [0.08539355]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fa6Qj_JSqbWc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}